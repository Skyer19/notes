# 定义
the specific definition of RAG refers to the model, when answering questions or generating text, first retrieving relevant information from a vast corpus of documents. Subsequently, it utilizes this retrieved information to generate responses or text, thereby enhancing the quality of predictions.

RAG（Retrieval-Augmented Generation） 是一种将「检索（Retrieval）」与「生成（Generation）」相结合的文本生成与问答框架，最初由 Facebook AI（Meta AI）提出。它的核心思想是：在文本生成或问答的过程中，不仅依赖模型本身的参数去“记忆”大规模知识，还可以实时从外部知识库中检索到最相关的文档或片段，并将这些信息与生成模型的隐状态相结合，从而更好地回答问题或生成文本。

核心思想是：在文本生成或问答的过程中，不仅依赖模型本身的参数去“记忆”大规模知识，还可以实时从外部知识库中检索到最相关的文档或片段，并将这些信息与生成模型的隐状态相结合，从而更好地回答问题或生成文本。

# RAG 的整体流程

## 用户输入（Query）

用户提出一个查询，比如一个开放域的问题（“世界上最高的山是哪座？”）。这一查询将被输入到整个 RAG 系统。

## 查询向量化

在向量检索过程中，首先需要将用户的自然语言问题转换为可用于检索的向量表示，即通过一个**编码器（Encoder）**将文本映射到固定维度的向量空间。

- 常用的编码器可以是 BERT、DPR (Dense Passage Retriever)、Sentence-BERT，或者其他专门用于检索任务的预训练模型。
- 这个过程中的目标是让语义相似度更高的句子或文本片段在向量空间中的距离更近。

## 外部知识库的向量化

RAG 需要事先准备一个外部知识库，其中包含大量文本（可以是段落、文档、网页片段等）。

- 在向量检索阶段前，一般会把这些文本预先分割成一定大小的段落（passage），例如 100 ~ 300 个词的片段。

原因：
<pre>
上下文管理：
在实际应用中，尤其是大规模文本（如维基百科、新闻、企业文档）里，单个文档往往很长。将整篇文档直接做向量化，会导致以下问题：

粒度过粗：当文档非常长时，其向量往往难以精准地表示文档内部的局部信息。
召回困难：如果只用一个向量来代表整个长文本，查询时就难以准确检索到文档中的具体段落，导致检索结果过于宽泛。
模型上下文限制：许多模型（例如 BERT、GPT）在处理时，对输入序列的长度是有限制的（常见 512 ~ 4096 tokens 不等），将文档拆分成小块能更好地适配这些模型进行后续处理。
提升检索准确度与效率：
把文档分割成更短、更聚焦的段落（passage，常见长度是 100 ~ 300 词），可以让系统在进行检索时更容易找到与查询最相关的那部分内容，并且在后续做重排序或阅读理解时，也能减少无关信息的干扰。

更精确的答复：
对于问答或文本生成任务来说，系统更需要“特定段落”级别的内容，而不是整个文档。通过在检索阶段就能直接定位到最相关的段落，后续阶段的生成模型或阅读理解模型就可以直接利用这些信息，显著提高答案的准确度。
</pre>

- 然后使用与“查询向量化”相同或相似的模型，对这些文本段落进行向量化。

主要流程：
'''py
选择合适的编码器（Encoder）：

常见的向量编码器包括 BERT、Sentence-BERT、DPR (Dense Passage Retriever) 等。
理想情况下，对段落和对查询都使用相同或相似结构的模型进行向量化，保证它们在同一个语义空间中可比较。
将段落输入编码器：

对于每个段落，将其输入到预训练或微调后的编码器（例如 BERT 的 [CLS] 向量、Sentence-BERT 的输出向量、DPR 的输出向量），获取一个固定维度的向量，例如 768 维或 1024 维。
这些向量捕捉了文本段落在语义层面的主要信息。
归一化（可选）：

很多向量检索系统会在向量化后对向量进行归一化（L2 Normalization），便于后续使用余弦相似度进行检索。
也有系统选择直接使用点积或欧几里得距离，依实际需要而定。
存储：

最终得到的向量会和对应文本段落的元数据信息（如段落内容、文档 ID、章节信息、时间戳）一起存储，以便在检索到该向量时，能够方便地回溯到具体的文本内容。
'''

- 将向量存储在一个**向量索引（Vector Index）**里，并可以使用诸如 FAISS、Milvus、Elastic Vector Search 等技术来高效进行相似度搜索。

<pre>
1.	DPR (Dense Passage Retriever)
    RAG 论文中最常用的检索组件之一。
    通过一个双塔（双编码器）结构，将问题和文档分别编码为向量；然后计算它们的内积以衡量相似度。
    在训练时利用大型问答数据集，采用对比学习（Contrastive Learning）来拉近正样本（正确答案所在文档）与问题的向量距离，推远负样本的距离。
    DPR 通常与 BERT 或 RoBERTa 类模型结合，用于开放域问答。

2.	FAISS
    由 Facebook AI 开源的向量检索库，实现了高效的相似度（内积或向量距离）计算和近似最近邻搜索。
    提供了多种索引结构（Flat、IVF、PQ、HNSW 等），可以根据数据规模、内存与检索精度需求选择合适的方案。
    常被用来构建 RAG 的底层向量索引部分。

3.	HNSW / Annoy / Milvus
    除了 FAISS 之外，也常用 HNSW（Hierarchical Navigable Small World 图结构）、Annoy、Milvus 等向量数据库或检索库来实现高效的 ANN 搜索。
    具体选择往往取决于数据量级、查询延时、分布式需求、部署环境等因素。

4.	聚合与精排
    对检索到的 Top-k 结果进行聚合或精排（Re-ranking），可以结合一些传统检索方法（BM25）或者微调的交叉编码器（Cross-Encoder），进一步提升检索质量。
    在 RAG 中，往往会采用先用向量检索快速选出一批候选文档，再用更精细的排序模型来重新打分，选出与问题最匹配的一些文档片段。

5.	多轮检索与迭代增强
    一些增强版的 RAG 会进行多轮检索，即先检索出文档后，模型基于初步阅读的结果，再形成新的检索查询，进行二次或多次检索，从而逐步缩小范围，找到更加精准的答案。
    也有的模型会把检索过程与推理过程紧密结合，形成“检索-生成-检索-生成”的循环。
</pre>

## 基于向量相似度的检索
当获取了查询向量后，RAG 就会在预先构建的向量索引中，按照余弦相似度（Cosine Similarity）、内积（Dot Product）或欧几里得距离（L2 Distance）等度量方式，检索出与该查询最相似的若干个文档片段（Top-k）。
举例来说，如果我们需要检索 5 篇相关内容，就会返回与查询向量距离最近的前 5 个文档段落。

## 融合检索到的文档信息进行生成
将检索到的文档（Top-k 段落）与原始查询一起输入到一个生成模型（例如 BART、T5、GPT 等）中，通过注意力机制（Attention）或特定的融合方式，综合利用外部知识与模型内部参数完成生成。
这个过程可以是一个单步或多步的推理过程，也可以结合强化学习或其他策略。

## 输出最终结果
最终生成模型会输出一段文本，回答用户的问题或完成某个文本生成的目标。

# 与大型语言模型结合的灵活性
RAG 之所以有效，是因为它把外部知识检索与语言模型的生成能力结合起来:

- 大模型（PLM）负责语言理解与生成。
- 向量检索负责拉取最相关的信息。
- 双管齐下，不仅能提升信息准确性，还能减少纯依赖大模型记忆带来的参数膨胀。

可更新性
当外部世界的信息变化时（例如新科技、新新闻出现），只要更新向量索引（重新插入或替换文档向量），模型就能在下次检索时获取到最新的知识，而不需要重新训练或微调大型语言模型本身。

# RAG的调优

- 预训练阶段，例如用MLM的模式
- 微调阶段，可操作的除了大模型本身，拓展到检索器、生成器的优化，一方面能单独提升其中一个的效果，也能够两者联合训练，提升两者各自能力的同时提升他们的系统配合能力。
- 推理阶段，即融合检索结果与大模型，例如增加知识引导、跨语言、思维链引导等

# RAG 数据来源的分类

### 非结构化数据（纯文本）
典型例子：文章、博客、新闻报道、学术论文、维基百科词条等。

- 特点：没有固定的结构化字段，主要是自然语言文本，长度和语言风格各异。
- 处理方式：通常先对长文档做分割（chunking），再对每个“段落”进行向量化和索引。
- 优点：信息量大、覆盖面广，适合开放域问答或文本生成。
- 缺点：检索后常需进一步的阅读理解或信息抽取才能回答具体问题。

### 半结构化数据（带标签或键值）
典型例子：HTML 网页、JSON、XML、日志文件、论坛帖子等。

- 特点：整体仍以文本为主，但包含一定的标记（如标签、层级、键值对），可以帮助模型或检索工具利用特定字段进行过滤或排序。
- 处理方式：通常先进行数据清洗（剥离或解析出文本字段、时间戳、作者、标题等），然后对关键内容进行向量化。
- 优势：可以灵活地利用元数据（如发布时间、作者、类别）进行检索前的筛选（Filter），或者在检索结果中进行再排序。

### 结构化数据（表格、知识图谱）
典型例子：关系型数据库中的表格、知识图谱（Knowledge Graph）、Excel 表格、API 返回的字段等。

- 特点：有明确定义的字段、类型、行列结构，或者实体-关系形式。
- 处理方式：可以将表格中的单元格、行、列或知识图谱中的实体-属性描述转换成自然语言表述，再进行向量化；也可以直接用专门的图向量或表格编码器进行嵌入。
- 优势：信息精确、查询效率高，适合回答特定的事实性问题（如数值、日期、属性等）。

